## 时延

### 单向时延

< 150ms					人感觉不到

150ms ~~ 450ms	人耳	

### 时延产生

![](.\png\时延产生.png)

从上图看出，传输过程包括三部分，一是从发送端采集到语音数据处理后发送到网络设备，二是网络设备之间传送，三是从网络设备发送给接收端并播放出来。

#### 时延分类

1. 通信终端上引入的时延
2. 通信终端和网络设备之间的时延，包括采集终端到网络设备的延时和网络设备到播放设备的延时
3. 网络设备之间的时延



### 通讯终端引入的时延

#### 采集端

发送端主要包括声音的采集引入的延时、前处理算法引入的延时和编码算法引入的时延。声音采集时通常5Ms或者10Ms从采集DMA中取一次语音数据，但是编码时多数codec要求的一帧是20Ms（比如AMR-WB），这两者之间不匹配，就要求采集到的数据放在buffer里缓一段时间，等到帧长时再取出来去编码，这就引入了时延。以一帧20Ms为例，就会引入20Ms的延时。前处理算法主要有AEC、ANS、AGC，这些算法都会引入延时，这跟滤波器的阶数有关，阶数越多，延时越大。编码算法同前处理算法一样也引入了延时。

#### 接收端

接收端主要包括端网络延时、解码算法延时、后处理算法延时和播放延时。端网络延时主要出现在解码之前的jitter buffer内，如果有抗丢包处理（例如FEC）延时还会增加（有FEC增加延时的原因是要等接收到的包到指定个数才能做FEC解码还原出原始包。解码和后处理算法和发送端的编码前处理类似有延时。播放前为了保持播放的流畅性会在语音数据进播放DMA前加一级buffer，这也引入了延时。

#### 时延测量

搭建一个理想的端到端的语音通信系统（理想是指网络几乎不引入时延），同时两端均采用该语音方案，这样就可以用仪器测出端到端的延时了。测时延时，仪器上显示的时延是一个平均值，等通话时长达到一定值后就会稳定下来。



有些模块引入的时延是已知固定的，且不能减少，比如信号处理算法模块。有些模块引入的时延是未知的，我们就需要去测量这个模块引入的时延具体是多少。做这些前需要对该语音通信方案的软件架构熟悉，知道方案中有几个（除了信号处理算法模块外）引入时延的点。这种时延通常是对buffer的存取引入的时间差，该怎么测出时延值呢？我一般用如下的方法：当把语音数据放进buffer时记下当时的时间t1，保存在这段数据开始的地方（虽然破坏了语音数据，不过没关系，我们只是用来测延时，是一种手段，不关心语音质量），当从buffer中取出这段语音数据时，再记录下时间t2，将t2减去保存在数据中的t1就得到本次存取引入的延时。统计非常多次（我通常用一万次）再算平均值，就可以得到这个点引入的时延了。

#### 时延减小的方法

##### 用减小缓冲深度来减小时延

这种方法说白了就是让语音数据在buffer里呆的时间短些，比如以前在buffer里有了3帧（假设每帧20Ms）语音数据才会从buffer中取出给下一模块，这样平均就会引入60Ms的时延。如果将3帧改为2 帧，则平均引入的时延就降为40Ms，这样就减少了20Ms的时延。不过用这种方法是有条件的，要确保语音质量不下降。

##### 用加速信号处理算法来减少时延

音频信号处理中有个算法叫加速，它是对PCM信号进行处理，在不丢失语音信息的前提下把时长减小，它的原理是WSOLA。比如原PCM数据时长是5秒，经过加速处理后变成了4秒，人听上去信息没丢失，但是语速变快了。如果在buffer中待播放的PCM数据较长，肯定延时较大，可以通过这种加速算法把要播放的数据处理一下，变成短时长的PCM数据，这样就可以减小延时了。webRTC 中的netEQ就有用加速算法来减小延时的功能。

